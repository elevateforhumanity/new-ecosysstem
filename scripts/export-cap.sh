#!/bin/bash
set -euo pipefail

# Export Cap Script - Only deploy priority pages
# Usage: ./scripts/export-cap.sh [LIMIT] [OUTPUT_DIR]

LIMIT=${1:-100}  # Default to 100 pages
OUT=${2:-"dist"} # Default output directory
MANIFEST="export-manifest.txt"

echo "ğŸš€ Starting capped export (limit: $LIMIT pages)"

# Clean output directory
rm -rf "$OUT"
mkdir -p "$OUT"

# Create priority manifest if it doesn't exist
if [ ! -f "$MANIFEST" ]; then
    echo "ğŸ“ Creating priority manifest..."
    cat > "$MANIFEST" << 'EOF'
/
/programs/
/programs/cybersecurity/
/programs/cloud-computing/
/programs/healthcare-cna/
/programs/electrical-trades/
/programs/construction/
/programs/beauty-wellness/
/about/
/employers/
/contact/
/blog/
/privacy/
/terms/
/accessibility/
/faq/
/sitemap.html
EOF
fi

# Process manifest and cap at limit
echo "ğŸ“‹ Processing manifest (first $LIMIT entries)..."
head -n "$LIMIT" "$MANIFEST" > /tmp/export-list.txt

# Copy essential files first
echo "ğŸ“ Copying essential files..."
cp -r assets/ "$OUT/" 2>/dev/null || echo "âš ï¸  No assets directory found"
cp robots.txt "$OUT/" 2>/dev/null || echo "âš ï¸  No robots.txt found"
cp sitemap_index.xml "$OUT/" 2>/dev/null || echo "âš ï¸  No sitemap_index.xml found"
cp -r sitemaps/ "$OUT/" 2>/dev/null || echo "âš ï¸  No sitemaps directory found"

# Copy pages from manifest
echo "ğŸ“„ Copying pages..."
COPIED=0
while IFS= read -r page_path; do
    # Skip empty lines and comments
    [[ -z "$page_path" || "$page_path" =~ ^# ]] && continue
    
    # Determine source file
    if [[ "$page_path" == "/" ]]; then
        src_file="index.html"
        dst_dir="$OUT"
        dst_file="$dst_dir/index.html"
    else
        # Remove leading/trailing slashes
        clean_path="${page_path#/}"
        clean_path="${clean_path%/}"
        
        src_file="${clean_path}/index.html"
        dst_dir="$OUT/$clean_path"
        dst_file="$dst_dir/index.html"
    fi
    
    # Copy if source exists
    if [ -f "$src_file" ]; then
        mkdir -p "$dst_dir"
        cp "$src_file" "$dst_file"
        echo "âœ… $page_path"
        ((COPIED++))
    else
        echo "âŒ $page_path (source not found: $src_file)"
    fi
done < /tmp/export-list.txt

# Generate deployment info
cat > "$OUT/deployment-info.json" << EOF
{
    "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
    "pages_exported": $COPIED,
    "export_limit": $LIMIT,
    "git_commit": "$(git rev-parse HEAD 2>/dev/null || echo 'unknown')",
    "git_branch": "$(git branch --show-current 2>/dev/null || echo 'unknown')"
}
EOF

echo ""
echo "ğŸ‰ Export complete!"
echo "ğŸ“Š Pages exported: $COPIED"
echo "ğŸ“ Output directory: $OUT"
echo "ğŸ’¾ Total size: $(du -sh "$OUT" | cut -f1)"

# List what was exported
echo ""
echo "ğŸ“‹ Exported pages:"
find "$OUT" -name "index.html" | sed "s|^$OUT||" | sed 's|/index.html$|/|' | sed 's|^$|/|' | sort

# Cleanup
rm -f /tmp/export-list.txt

echo ""
echo "ğŸš€ Ready for deployment!"
echo "   Deploy command: rsync -av $OUT/ your-server:/var/www/html/"
echo "   Or upload $OUT/ contents to your hosting provider"